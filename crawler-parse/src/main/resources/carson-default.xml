<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

	<property>
		<name>spider.master</name>
		<value>true</value>
		<description>只有一个是master</description>
	</property>

	<property>
		<name>spider.thread.num</name>
		<value>10</value>
		<description>本机器爬虫的线程数</description>
	</property>
	<property>
		<name>spider.parse.thread.max</name>
		<value>20</value>
		<description>一个URL种子的最大解析线程数</description>
	</property>
	<property> <!-- 解析器配置文件 -->
		<name>parse.plugin.file</name>
		<value>parse-plugins.xml</value>
		<description>The name of the file that defines the associations
			between
			content-types and parsers.
		</description>
	</property>

	<property> <!-- 种子seed类型配置文件 -->
		<name>seed.conf.file</name>
		<value>seed-confs.xml</value>
		<description>
		</description>
	</property>

	<!-- file properties -->

	<property>
		<name>file.content.limit</name>
		<value>1048576</value>
		<description>The length limit for downloaded content using the file
			protocol, in bytes. If this value is nonnegative
			(>=0), content longer
			than it will be truncated; otherwise, no truncation at all. Do not
			confuse this setting with the
			http.content.limit setting.
		</description>
	</property>

	<property>
		<name>http.agent.name</name>
		<value>Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.116 Safari/537.36</value>
		<description>HTTP 'User-Agent' request header. MUST NOT be empty -
			please set this to a single word uniquely related to
			your organization.

			NOTE: You should also check other related properties:

			http.robots.agents
			http.agent.description
			http.agent.url
			http.agent.email
			http.agent.version

			and set their values appropriately.

		</description>
	</property>

	<property>
		<name>http.timeout</name>
		<value>10000</value>
		<description>The default network timeout, in milliseconds.</description>
	</property>

	<property>
		<name>http.max.delays</name>
		<value>100</value>
		<description>The number of times a thread will delay when trying to
			fetch a page. Each time it finds that a host is
			busy, it will wait
			fetcher.server.delay. After http.max.delays attepts, it will give
			up on the page for now.
		</description>
	</property>

	<property>
		<name>http.content.limit</name>
		<value>65536</value>
		<description>The length limit for downloaded content using the http
			protocol, in bytes. If this value is nonnegative
			(>=0), content longer
			than it will be truncated; otherwise, no truncation at all. Do not
			confuse this setting with the
			file.content.limit setting.
		</description>
	</property>

	<property>
		<name>http.verbose</name>
		<value>true</value>
		<description>If true, HTTP will log more verbosely.</description>
	</property>

	<property>
		<name>http.useHttp11</name>
		<value>false</value>
		<description>NOTE: at the moment this works only for protocol-httpclient.
			If true, use HTTP 1.1, if false use HTTP 1.0
			.
		</description>
	</property>

	<property>
		<name>http.accept.language</name>
		<value>en-us,en-gb,en;q=0.7,*;q=0.3</value>
		<description>Value of the "Accept-Language" request header field.
			This allows selecting non-English language as default
			one to retrieve.
			It is a useful setting for search engines build for certain national group.
		</description>
	</property>

	<property>
		<name>http.accept</name>
		<value>text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8</value>
		<description>Value of the "Accept" request header field.
		</description>
	</property>

	<!-- fetcher properties -->

	<property>
		<name>fetcher.server.delay</name>
		<value>5.0</value>
		<description>The number of seconds the fetcher will delay between
			successive requests to the same server.
		</description>
	</property>

	<property>
		<name>fetcher.server.min.delay</name>
		<value>0.0</value>
		<description>The minimum number of seconds the fetcher will delay between
			successive requests to the same server. This
			value is applicable ONLY
			if fetcher.threads.per.host is greater than 1 (i.e. the host blocking
			is turned off).
		</description>
	</property>

	<property>
		<name>fetcher.max.crawl.delay</name>
		<value>30</value>
		<description>
			If the Crawl-Delay in robots.txt is set to greater than this value (in
			seconds) then the fetcher will skip
			this page, generating an error report.
			If set to -1 the fetcher will never skip such pages and will wait the
			amount of
			time retrieved from robots.txt Crawl-Delay, however long that
			might be.
		</description>
	</property>

	<property>
		<name>fetcher.threads.fetch</name>
		<value>10</value>
		<description>The number of FetcherThreads the fetcher should use.
			This is also determines the maximum number of
			requests that are
			made at once (each FetcherThread handles one connection). The total
			number of threads running in
			distributed mode will be the number of
			fetcher threads * number of nodes as fetcher has one map task per node.
		</description>
	</property>

	<property>
		<name>fetcher.threads.per.queue</name>
		<value>1</value>
		<description>This number is the maximum number of threads that
			should be allowed to access a queue at one time.
		</description>
	</property>

	<property>
		<name>fetcher.queue.mode</name>
		<value>byHost</value>
		<description>Determines how the URLs are placed into queues.
			Allowed values are 'byHost', 'byDomain' and 'byIP'.
			The
			value would usually correspond to that of 'partition.url.mode'.
		</description>
	</property>

	<property>
		<name>fetcher.queue.use.host.settings</name>
		<value>false</value>
		<description>Allows us to optionally enable host specific queue behavior if present.
		</description>
	</property>

	<property>
		<name>fetcher.verbose</name>
		<value>false</value>
		<description>If true, fetcher will log more verbosely.</description>
	</property>

	<property>
		<name>fetcher.parse</name>
		<value>false</value>
		<description>If true, fetcher will parse content. NOTE: previous releases would
			default to true. Since 2.0 this is set
			to false as a safer default.
		</description>
	</property>

	<property>
		<name>fetcher.store.content</name>
		<value>true</value>
		<description>If true, fetcher will store content.</description>
	</property>

	<property>
		<name>fetcher.timelimit.mins</name>
		<value>-1</value>
		<description>This is the number of minutes allocated to the fetching.
			Once this value is reached, any remaining entry
			from the input URL list is skipped
			and all active queues are emptied. The default value of -1 deactivates the time
			limit.
		</description>
	</property>

	<property>
		<name>fetcher.max.exceptions.per.queue</name>
		<value>-1</value>
		<description>The maximum number of protocol-level exceptions (e.g. timeouts) per
			host (or IP) queue. Once this value is
			reached, any remaining entries from this
			queue are purged, effectively stopping the fetching from this host/IP. The
			default
			value of -1 deactivates this limit.
		</description>
	</property>

	<property>
		<name>fetcher.throughput.threshold.pages</name>
		<value>-1</value>
		<description>The threshold of minimum pages per second. If the fetcher downloads less
			pages per second than the
			configured threshold, the fetcher stops, preventing slow queue's
			from stalling the throughput. This threshold must be
			an integer. This can be useful when
			fetcher.timelimit.mins is hard to determine. The default value of -1 disables this
			check.
		</description>
	</property>

	<property>
		<name>fetcher.throughput.threshold.sequence</name>
		<value>5</value>
		<description>The number of times the fetcher.throughput.threshold is allowed to be exceeded,
			in a row. This setting
			prevents accidental slow downs from stopping the fetcher.
		</description>
	</property>

	<property>
		<name>fetcher.throughput.threshold.check.after</name>
		<value>5</value>
		<description>The number of minutes after which the throughput check is enabled.</description>
	</property>

	<property>
		<name>fetcher.queue.depth.multiplier</name>
		<value>50</value>
		<description>(EXPERT)The fetcher buffers the incoming URLs into queues based on the [host|domain|IP]
			(see param
			fetcher.queue.mode). The depth of the queue is the number of threads times the value of this parameter.
			A large value
			requires more memory but can improve the performance of the fetch when the order of the URLS in the
			fetch list
			is not
			optimal.
		</description>
	</property>

	<!-- parser properties -->

	<property>
		<name>parse.plugin.file</name>
		<value>parse-plugins.xml</value>
		<description>The name of the file that defines the associations between
			content-types and parsers.
		</description>
	</property>

	<property>
		<name>parser.character.encoding.default</name>
		<value>windows-1252</value>
		<description>The character encoding to fall back to when no other information
			is available
		</description>
	</property>
	<property>
  <name>htmlparsefilter.order</name>
  <value></value>
  <description>The order by which HTMLParse filters are applied.
  If empty, all available HTMLParse filters (as dictated by properties
  plugin-includes and plugin-excludes above) are loaded and applied in system
  defined order. If not empty, only named filters are loaded and applied
  in given order.
  HTMLParse filter ordering MAY have an impact
  on end result, as some filters could rely on the metadata generated by a previous filter.
  </description>
</property>
</configuration>
